{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN-based Brain Tumour Segmentation Network\n",
    "## Import packages\n",
    "Please make sure you have all the required packages installed. If GPU is available, but you want to use CPU to train your model, make sure you add \" os.environ['CUDA_VISIBLE_DEVICES'] = '-1'.\n",
    "Package 'SimpleITK' is for loading the MR images, so you need to install it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise MRI Volume Slices and Segmentation Maps\n",
    "Each MRI image contains information about a three-dimensional (3D) volume of space. An MRI image is composed of a number of voxels, which is like pixels in 2D images. Here we visualise the transverse plane (usually has a higher resolution) of some of the volumes and the corresponding segmentation maps. If the size of an MRI image is 200x230x230, it means that there are 200 slices of 230x230 images in the transverse plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_samples(x,n=10):\n",
    "    i = n\n",
    "    j = 2\n",
    "    plt.figure(figsize=(15,20))\n",
    "    k = 1\n",
    "    idx_nums = np.random.randint(len(x),size=n)\n",
    "    for idx in idx_nums:\n",
    "        plt.subplot(i,j,k)\n",
    "        while k%2 != 0:\n",
    "            plt.imshow(np.load(x[idx])[:,:,0], cmap='gray')\n",
    "            plt.xlabel(\"Input\")\n",
    "            k += 1\n",
    "        plt.subplot(i,j,k)\n",
    "        plt.imshow(np.load(x[idx].split('_')[0]+'_seg.npy')[:,:], cmap='gray')\n",
    "        plt.xlabel(\"Ground Truth\")\n",
    "        k += 1\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "img_path = 'Dataset/'\n",
    "img_list = []\n",
    "CLASS = 'Yes'\n",
    "all_files = os.listdir(img_path + CLASS)\n",
    "files = [item for item in all_files if \"img\" in item]\n",
    "random.shuffle(files)\n",
    "img_num = len(files)\n",
    "for (n, file_name) in enumerate(files):\n",
    "    img = os.path.join(img_path,CLASS,file_name)\n",
    "    seg = os.path.join(img_path,CLASS,file_name.split('_')[0]+'_seg.npy')\n",
    "    img_list.append(img)\n",
    "plot_samples(img_list, n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "Images in the original dataset are usually in different sizes, so sometimes we need to resize and normalise (z-score is commonly used in preprocessing the MRI images) them to fit the CNN model. Depending on the images you choose to use for training your model, some other preprocessing methods. If preprocessing methods like cropping is applied, remember to convert the segmentation result back to its original size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-time data augmentation\n",
    "Generalizability is crucial to a deep learning model and it refers to the performance difference of a model when evaluated on the seen data (training data) versus the unseen data (testing data). Improving the generalizability of these models has always been a difficult challenge. \n",
    "\n",
    "**Data Augmentation** is an effective way of improving the generalizability, because the augmented data will represent a more comprehensive set of possible data samples and minimizing the distance between the training and validation/testing sets.\n",
    "\n",
    "There are many data augmentation methods you can choose in this projects including rotation, shifting, flipping, etc.\n",
    "\n",
    "You are encouraged to try different augmentation method to get the best segmentation result.\n",
    "\n",
    "\n",
    "## Get the data generator ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, batch_size=32, dim=(240,240), n_channels=3,\n",
    "                 n_classes=2, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, Y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, Y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim, 1))\n",
    "        Y = np.empty((self.batch_size, *self.dim, 2))\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            # Add data augmentation here\n",
    "            img = np.load(ID)[:,:,0]\n",
    "            img = np.expand_dims(img, axis=2)\n",
    "            X[i,] = img\n",
    "\n",
    "            # Store class\n",
    "            label = np.load(ID.split('_')[0]+'_seg.npy')\n",
    "            label = np.expand_dims(label, axis=2)\n",
    "            label = np.concatenate(((-label)+1, label),axis=-1)\n",
    "            Y[i,] = label\n",
    "\n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2656\n",
      "663\n"
     ]
    }
   ],
   "source": [
    "train_list = []\n",
    "val_list = []\n",
    "\n",
    "train_root = 'Train/Yes'\n",
    "for path in os.listdir(train_root):\n",
    "    if path.split(\".\")[0].split(\"_\")[1] == \"img\":\n",
    "        train_list.append(os.path.join(train_root, path))\n",
    "val_root = 'Val/Yes'\n",
    "for path in os.listdir(val_root):\n",
    "    if path.split(\".\")[0].split(\"_\")[1] == \"img\":\n",
    "        val_list.append(os.path.join(val_root, path))\n",
    "\n",
    "print(len(train_list))\n",
    "print(len(val_list))\n",
    "\n",
    "train_generator = DataGenerator(train_list)\n",
    "validation_generator = DataGenerator(val_list)\n",
    "img_size = (240,240)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a metric for the performance of the model\n",
    "Dice score is used here to evaluate the performance of your model.\n",
    "More details about the Dice score and other metrics can be found at \n",
    "https://towardsdatascience.com/metrics-to-evaluate-your-semantic-segmentation-model-6bcb99639aa2. Dice score can be also used as the loss function for training your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    def dice_coef(y_true, y_pred, smooth=1.0):
    ''' Dice Coefficient
    Args:
        y_true (np.array): Ground Truth Heatmap (Label)
        y_pred (np.array): Prediction Heatmap
    '''
    class_num = 2
    for i in range(class_num):
        y_true_f = K.flatten(y_true[:,:,:,i])
        y_pred_f = K.flatten(y_pred[:,:,:,i])
        intersection = K.sum(y_true_f * y_pred_f)
        loss = ((2. * intersection + smooth) / 
                (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))
        if i == 0:
            total_loss = loss
        else:
            total_loss = total_loss + loss
    total_loss = total_loss / class_num
    return total_loss

def dice_coef_loss(y_true, y_pred):
    ''' Dice Coefficient Loss
    Args:
        y_true (np.array): Ground Truth Heatmap (Label)
        y_pred (np.array): Prediction Heatmap
    '''
    return 1-dice_coef(y_true, y_pred)

'''def focal_loss(y_true, y_pred):
    gamma=0.75
    alpha=0.25
    class_num = 2
    for i in range (class_num):  
        y_true_f = K.flatten(y_true[:,:,:,i])
        y_pred_f = K.flatten(y_pred[:,:,:,i])
        
        pt_1 = tf.where(tf.equal(y_true_f, 1), y_pred_f, 
                        tf.ones_like(y_pred_f))
        pt_0 = tf.where(tf.equal(y_true_f, 0), y_pred_f, 
                        tf.zeros_like(y_pred_f))
 
        pt_1 = K.clip(pt_1, 1e-3, .999)
        pt_0 = K.clip(pt_0, 1e-3, .999)
    
        loss = -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))
        if i == 0:
            total_loss = loss
        else:
            total_loss = total_loss + loss
    total_loss = total_loss / class_num
    return total_loss'''

def tversky(y_true, y_pred, alpha=0.7):
    smooth = 1
    class_num = 2
    for i in range (class_num):  
        y_true_pos = K.flatten(y_true[:,:,:,i])
        y_pred_pos = K.flatten(y_pred[:,:,:,i])
        true_pos = K.sum(y_true_pos * y_pred_pos)
        false_neg = K.sum(y_true_pos * (1-y_pred_pos))
        false_pos = K.sum((1-y_true_pos)*y_pred_pos)
        loss = (true_pos + smooth)/(true_pos + alpha*false_neg + (1-alpha)*false_pos + smooth)
        if i == 0:
            total_loss = loss
        else:
            total_loss = total_loss + loss
    total_loss = total_loss / class_num
    return total_loss

def tversky_loss(y_true, y_pred):
    return 1 - tversky(y_true,y_pred)

def focal_tversky(y_true,y_pred):
    pt_1 = tversky(y_true, y_pred)
    gamma = 0.75
    return K.pow((1-pt_1), gamma)

'''def focal_dice_loss(y_true,y_pred):
    alpha = 0.25
    return alpha * focal_loss(y_true,y_pred) - K.log(dice_coef_loss(y_true,y_pred))'''
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build your own model here\n",
    "The U-Net (https://link.springer.com/chapter/10.1007/978-3-319-24574-4_28) structure is widely used for the medical image segmentation task. You can build your own model or modify the UNet by changing the hyperparameters for our task. If you choose to use Keras, more information about the Keras layers including Conv2D, MaxPooling and Dropout can be found at https://keras.io/api/layers/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 240, 240, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 240, 240, 32) 320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 240, 240, 32) 9248        conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 120, 120, 32) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 120, 120, 64) 18496       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 120, 120, 64) 36928       conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 60, 60, 64)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 60, 60, 128)  73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 60, 60, 128)  147584      conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 30, 30, 128)  0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 30, 30, 256)  295168      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 30, 30, 256)  590080      conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 15, 15, 256)  0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 15, 15, 512)  1180160     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 15, 15, 512)  2359808     conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 30, 30, 256)  524544      conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 30, 30, 512)  0           conv2d_transpose[0][0]           \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 30, 30, 256)  1179904     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 30, 30, 256)  590080      conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 60, 60, 128)  131200      conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 60, 60, 256)  0           conv2d_transpose_1[0][0]         \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 60, 60, 128)  295040      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 60, 60, 128)  147584      conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 120, 120, 64) 32832       conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 120, 120, 128 0           conv2d_transpose_2[0][0]         \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 120, 120, 64) 73792       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 120, 120, 64) 36928       conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 240, 240, 32) 8224        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 240, 240, 64) 0           conv2d_transpose_3[0][0]         \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 240, 240, 32) 18464       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 240, 240, 32) 9248        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 240, 240, 2)  66          conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 240, 240, 2)  0           conv2d_18[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 7,759,554\n",
      "Trainable params: 7,759,554\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ecurb\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    }
   ],
   "source": [
    "from keras import initializers\n",
    "\n",
    "input_size = (240,240,1)\n",
    "\n",
    "inputs = Input(input_size)\n",
    "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same',\n",
    "                kernel_initializer=initializers.random_normal(stddev=0.01))(inputs)\n",
    "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same',\n",
    "                kernel_initializer=initializers.random_normal(stddev=0.01))(conv1)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same',\n",
    "                kernel_initializer=initializers.random_normal(stddev=0.01))(pool1)\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same',\n",
    "                kernel_initializer=initializers.random_normal(stddev=0.01))(conv2)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same',\n",
    "               kernel_initializer=initializers.random_normal(stddev=0.01))(pool2)\n",
    "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same',\n",
    "               kernel_initializer=initializers.random_normal(stddev=0.01))(conv3)\n",
    "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "conv4 = Conv2D(256, (3, 3), activation='relu', padding='same',\n",
    "               kernel_initializer=initializers.random_normal(stddev=0.01))(pool3)\n",
    "conv4 = Conv2D(256, (3, 3), activation='relu', padding='same',\n",
    "               kernel_initializer=initializers.random_normal(stddev=0.01))(conv4)\n",
    "pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "conv5 = Conv2D(512, (3, 3), activation='relu', padding='same',\n",
    "               kernel_initializer=initializers.random_normal(stddev=0.01))(pool4)\n",
    "conv5 = Conv2D(512, (3, 3), activation='relu', padding='same',\n",
    "               kernel_initializer=initializers.random_normal(stddev=0.01))(conv5)\n",
    "\n",
    "up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same',\n",
    "            kernel_initializer=initializers.random_normal(stddev=0.01))(conv5),conv4], axis=3)\n",
    "conv6 = Conv2D(256, (3, 3), activation='relu', padding='same',\n",
    "               kernel_initializer=initializers.random_normal(stddev=0.01))(up6)\n",
    "conv6 = Conv2D(256, (3, 3), activation='relu', padding='same',\n",
    "               kernel_initializer=initializers.random_normal(stddev=0.01))(conv6)\n",
    "\n",
    "up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same',\n",
    "            kernel_initializer=initializers.random_normal(stddev=0.01))(conv6),conv3], axis=3)\n",
    "conv7 = Conv2D(128, (3, 3), activation='relu', padding='same',\n",
    "               kernel_initializer=initializers.random_normal(stddev=0.01))(up7)\n",
    "conv7 = Conv2D(128, (3, 3), activation='relu', padding='same',\n",
    "               kernel_initializer=initializers.random_normal(stddev=0.01))(conv7)\n",
    "\n",
    "up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2),padding='same',\n",
    "            kernel_initializer=initializers.random_normal(stddev=0.01))(conv7),conv2], axis=3)\n",
    "conv8 = Conv2D(64, (3, 3), activation='relu', padding='same',\n",
    "               kernel_initializer=initializers.random_normal(stddev=0.01))(up8)\n",
    "conv8 = Conv2D(64, (3, 3), activation='relu', padding='same',)(conv8)\n",
    "\n",
    "up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same',\n",
    "            kernel_initializer=initializers.random_normal(stddev=0.01))(conv8),conv1], axis=3)\n",
    "conv9 = Conv2D(32, (3, 3), activation='relu', padding='same',\n",
    "               kernel_initializer=initializers.random_normal(stddev=0.01))(up9)\n",
    "conv9 = Conv2D(32, (3, 3), activation='relu', padding='same',\n",
    "               kernel_initializer=initializers.random_normal(stddev=0.01))(conv9)\n",
    "\n",
    "conv10 = Conv2D(2, (1, 1), activation='relu',\n",
    "                kernel_initializer=initializers.random_normal(stddev=0.01))(conv9)\n",
    "conv10 = Activation('softmax')(conv10)\n",
    "model = Model(inputs=[inputs], outputs=[conv10])\n",
    "\n",
    "try:\n",
    "    lr = args.lr\n",
    "except:\n",
    "    lr = 1e-4\n",
    "model.compile(optimizer=Adam(lr=lr), loss=dice_coef_loss, metrics=[dice_coef])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train your model here\n",
    "Once you defined the model and data generator, you can start training your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2\n",
    "earlystopping = EarlyStopping(\n",
    "    monitor=dice_coef, \n",
    "    mode='max',\n",
    "    patience=20\n",
    ")\n",
    "\n",
    "from keras import callbacks\n",
    "# history = model.fit(\n",
    "#     train_generator,\n",
    "#     epochs=num_epochs,\n",
    "#     validation_data=validation_generator,\n",
    "#     callbacks=[earlystopping]\n",
    "# )\n",
    "\n",
    "model.fit_generator(train_generator, epochs=num_epochs,\n",
    "                validation_data=validation_generator, workers=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model\n",
    "Once your model is trained, remember to save it for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model on the test set\n",
    "After your last Q&A session, you will be given the test set. Run your model on the test set to get the segmentation results and submit your results in a .zip file. If the MRI image is named '100_fla.nii.gz', save your segmentation result as '100_seg.nii.gz'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files_path = 'Dataset/test'\n",
    "\"\"\"\n",
    "Example of saving the prediction result (numpy array) into .nii.gz file:\n",
    "\n",
    "sitk.save(pred, os.path.join(test_file_path,id,f'{id}_seg.nii'))\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
